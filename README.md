# bdlocal 基于 T5 和BERT 微调模型的长文本情绪分析方案

# 摘要
情绪分析是大数据分析中重要的一部分，在互联网时代的今天，分析网络上的言
论中蕴含的情绪可以快速掌握大众的情绪，对于分析公司和金融行业具有
重要的实际意义和价值。本文使用自然语言处理的方法进行迁移学习，基于T5 和BERT
微调的Transformer 模型，提出了一种可以分析长文本情绪的解决方案，并展示了相应
的 python 脚本的运行情况，为在生产生活中实际运用情绪分析提供了一种解决方法和
思路。 

关键词：情绪分析；机器学习；自然语言处理；Transformer；大数据；迁移学习


# 数据处理脚本性能分析

## 仅摘要生成所用时间和仅情绪分析所用时间 
脚本正常运行的过程中由于分为摘要生成和情绪分析两个步骤串联执行，故本文
还对其中每一种操作所花费时间进行了分析：
在注释掉情绪分析的相关代码之后，本文得到了只读取数据进行摘要生成所花费
的时间：

![image](https://user-images.githubusercontent.com/77398134/180682015-a1573692-6c0e-45ae-973e-d8725ffb5e75.png)

在注释掉摘要生成的相关代码之后，情绪分析模型出现了错误，提示输入的字符
串超出了模型所能接受的最大长度，即 512 个分词。本文选择采取截取数据的方式，
如果数据长度超出512，则只选取前510 个分词作为情绪分析模型的输入，后面的部分
直接丢弃的方法继续进行实验。由此本文得到了只读取数据进行情绪分析所花费的时
间：

![image](https://user-images.githubusercontent.com/77398134/180682028-c204721a-321b-4b13-ae03-fa3f8dc6cc81.png)


本文在对比上述时间区别之后发现，摘要生成所花费的时间占据了大部分的脚本
运行时间，仅生成摘要用时是仅进行情绪分析的50.445倍。 
由此可知脚本对于短篇文字的情绪分析效率将会优于对长篇文字的分析效率，因
为短篇文字不需要进行摘要生成，可以直接被情绪分析模型接受。所以本文提出的脚
本在分析微博、推特等有比较低的字数限制的社交媒体言论的时候将会更加高效。 

## 正常运行所用时间 
按照该数据集的词数计算，脚本的处理的平均速度为81.499词/秒。 
人类平均阅读英文的速度平均为 250 词/分，也就是 4.17 词/秒。拥有吉尼斯认证的
全世界阅读英文最快的人的阅读速度为平均值的 10 倍，即41.67 词/秒。本文提出的脚
本运行速度已经是阅读最快的人的8.150倍，是平均值的 81.499 倍。这意
味着在没有计算填写数据的情况下，在个人电脑上运行的脚本的已经可以替代 81 个人
同时进行阅读和总结，成功达到了本文提出的目标。如果本脚本运行在算力更强大的
服务器集群上，其将可以真正发挥出大数据分析的优势，对网络上庞大的文字数据进
行情感分析。
